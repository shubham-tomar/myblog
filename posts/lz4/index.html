<!doctype html><html lang=en><head><meta charset=UTF-8><meta content="IE=edge" http-equiv=X-UA-Compatible><meta content="width=device-width,initial-scale=1.0" name=viewport><title>
         LZ4 compression algorithm : A Deep Dive
        
    </title><meta content="LZ4 compression algorithm : A Deep Dive" property=og:title><meta content="LZ4 is a lossless compression algorithm based on the LZ77 algorithm. It compresses data by identifying repeating patterns and encoding them in a compact format. The focus of LZ4 is on high-speed compression and decompression, making it suitable for real-time applications where performance is critical." property=og:description><meta content="LZ4 is a lossless compression algorithm based on the LZ77 algorithm. It compresses data by identifying repeating patterns and encoding them in a compact format. The focus of LZ4 is on high-speed compression and decompression, making it suitable for real-time applications where performance is critical." name=description><link href=/icon/favicon.png rel=icon type=image/png><link href=https://shubham-tomar.github.io/myblog/fonts.css rel=stylesheet><link href=https://shubham-tomar.github.io/myblog/atom.xml rel=alternate title=shubham-tomar type=application/atom+xml><link href=https://shubham-tomar.github.io/myblog/theme/light.css rel=stylesheet><link href=https://shubham-tomar.github.io/myblog/theme/dark.css id=darkModeStyle rel=stylesheet><script src=https://shubham-tomar.github.io/myblog/js/themetoggle.js></script><script>setTheme(getSavedTheme())</script><link href=https://shubham-tomar.github.io/myblog/main.css media=screen rel=stylesheet><body><div class=wrapper><div class=sidebar id=sidebar><button class=sb-toggle-button id=sidebarToggle>☰</button><nav class=table-of-contents><ul><li><a href=https://shubham-tomar.github.io/myblog/posts/lz4/#intorduction>Intorduction</a><li><a href=https://shubham-tomar.github.io/myblog/posts/lz4/#what-is-lz4>What is LZ4?</a><li><a href=https://shubham-tomar.github.io/myblog/posts/lz4/#how-does-lz4-work>How Does LZ4 Work?</a> <ul><li><a href=https://shubham-tomar.github.io/myblog/posts/lz4/#the-building-blocks>The Building Blocks</a><li><a href=https://shubham-tomar.github.io/myblog/posts/lz4/#example-walkthrough-of-compression>Example walkthrough of compression</a><li><a href=https://shubham-tomar.github.io/myblog/posts/lz4/#example-walkthrough-of-decompression>Example walkthrough of decompression</a></ul><li><a href=https://shubham-tomar.github.io/myblog/posts/lz4/#best-suited-data-types-for-lz4>Best-Suited Data Types for LZ4</a><li><a href=https://shubham-tomar.github.io/myblog/posts/lz4/#data-types-less-suitable-for-lz4>Data Types Less Suitable for LZ4</a><li><a href=https://shubham-tomar.github.io/myblog/posts/lz4/#optimization-tips-for-using-lz4-in-columnar-databases>Optimization Tips for Using LZ4 in Columnar Databases</a><li><a href=https://shubham-tomar.github.io/myblog/posts/lz4/#conclusion>Conclusion</a></ul></nav><blockquote>"Success is no accident. It is hard work, perseverance, learning, studying, sacrifice and most of all, love of what you are doing or learning to do." — Pelé</blockquote></div><div class=content id=content><header class=navbar><div class=main><a href=https://shubham-tomar.github.io/myblog/>shubham-tomar</a><div class=socials><a rel="me noopener noreferrer" class=social href=https://github.com/shubham-tomar/ target=_blank> <img alt=github src=https://shubham-tomar.github.io/myblog/social_icons/github.svg> </a><a rel="me noopener noreferrer" class=social href=https://linkedin.com/in/shubham-tomar-cs/ target=_blank> <img alt=linkedin src=https://shubham-tomar.github.io/myblog/social_icons/linkedin.svg> </a></div></div><nav><a href=https://shubham-tomar.github.io/myblog/posts style=margin-left:.7em>/posts</a><a href=https://shubham-tomar.github.io/myblog/projects style=margin-left:.7em>/projects</a><a href=https://shubham-tomar.github.io/myblog/about style=margin-left:.7em>/about</a><a href=https://shubham-tomar.github.io/myblog/tags style=margin-left:.7em>/tags</a><a onclick="toggleTheme(); event.preventDefault();" href=# id=dark-mode-toggle> <img alt=Light id=sun-icon src=https://shubham-tomar.github.io/myblog/feather/sun.svg style=filter:invert(1)> <img alt=Dark id=moon-icon src=https://shubham-tomar.github.io/myblog/feather/moon.svg> </a><script>updateItemToggleTheme()</script></nav></header><main><article><div class=title><div class=page-header>LZ4 compression algorithm : A Deep Dive<span class=primary-color style=font-size:1.6em>.</span></div><div class=meta>Posted on <time>2024-12-06</time></div></div><h1>Table of Contents</h1><ul><li><a href=https://shubham-tomar.github.io/myblog/posts/lz4/#intorduction>Intorduction</a><li><a href=https://shubham-tomar.github.io/myblog/posts/lz4/#what-is-lz4>What is LZ4?</a><li><a href=https://shubham-tomar.github.io/myblog/posts/lz4/#how-does-lz4-work>How Does LZ4 Work?</a> <ul><li><a href=https://shubham-tomar.github.io/myblog/posts/lz4/#the-building-blocks>The Building Blocks</a></li><ul><li><a href=https://shubham-tomar.github.io/myblog/posts/lz4/#sliding-window-dictionary>Sliding Window(Dictionary)</a><li><a href=https://shubham-tomar.github.io/myblog/posts/lz4/#tokens>Tokens</a><li><a href=https://shubham-tomar.github.io/myblog/posts/lz4/#hash-table>Hash Table</a></ul><li><a href=https://shubham-tomar.github.io/myblog/posts/lz4/#example-walkthrough-of-compression>Example walkthrough of compression</a><li><a href=https://shubham-tomar.github.io/myblog/posts/lz4/#example-walkthrough-of-decompression>Example walkthrough of decompression</a></ul><li><a href=https://shubham-tomar.github.io/myblog/posts/lz4/#best-suited-data-types-for-lz4>Best-Suited Data Types for LZ4</a><li><a href=https://shubham-tomar.github.io/myblog/posts/lz4/#data-types-less-suitable-for-lz4>Data Types Less Suitable for LZ4</a><li><a href=https://shubham-tomar.github.io/myblog/posts/lz4/#optimization-tips-for-using-lz4-in-columnar-databases>Optimization Tips for Using LZ4 in Columnar Databases</a><li><a href=https://shubham-tomar.github.io/myblog/posts/lz4/#conclusion>Conclusion</a></ul><section class=body><img class=png src=/myblog/posts/lz4.png><h1 id=intorduction>Intorduction</h1><p>Data compression has become a cornerstone of efficient storage and faster data transfers. Among the myriad of compression algorithms available, LZ4 stands out for its speed. It achieves remarkable compression and decompression speeds while maintaining reasonable compression ratios. This blog explores the inner workings of LZ4, its practical use cases, and its advantages over other algorithms.<h1 id=what-is-lz4>What is LZ4?</h1><p>LZ4 is a lossless compression algorithm based on the LZ77 algorithm. It compresses data by identifying repeating patterns and encoding them in a compact format. The focus of LZ4 is on high-speed compression and decompression, making it suitable for real-time applications where performance is critical.<blockquote><p>It's also default compression algorithm for most Columnar DB like Clickhouse</blockquote><p>Key Features of LZ4<ul><li><code>High Speed:</code> Compression and decompression speeds of 400-500 MB/s per core. Ideal for scenarios where speed is more critical than compression ratio.<li><code>Small Memory Footprint:</code> LZ4 works with Sliding window approach reduces memory usage compared to dictionary-based algorithms.<li><code>Streaming-Friendly:</code> Supports block-based compression, making it suitable for streaming large data sets.</ul><h1 id=how-does-lz4-work>How Does LZ4 Work?</h1><p>LZ4 is based on the principles of the LZ77 algorithm. Put simply, it identifies repeating patterns in the data and replaces them with a reference to where they previously occurred. This reference is stored as an offset-length pair, which points to the location and size of the repeated sequence. Instead of storing duplicate data, LZ4 efficiently compresses it by specifying the position (offset) and how many bytes (length) to reuse from the previously processed data.<p>Now we will discuss in detail, how exactly it does that<h2 id=the-building-blocks>The Building Blocks</h2><ul><li><h3 id=sliding-window-dictionary>Sliding Window(Dictionary)</h3><li><p>LZ4 maintains a sliding window (default: 64 KB) to store the recently processed data.</p><li><p>This window acts as a "dictionary" to find repeating patterns.</p><li><p>It is not stored in the compressed file. It is transient and exists only in memory during compression and decompression</p><li><p><code>During compression:</code> Used to find matches in the input data.</p><li><p><code>During decompression:</code> Reconstructed incrementally by copying previously decompressed data into the output buffer.</p><li><h3 id=tokens>Tokens</h3></ul><p>The compressed data is represented as tokens, <strong>it is a single byte (8 bits)</strong> that serves as a compact descriptor for a segment of compressed data. It encodes two key pieces of information:<ul><li><code>Literals:</code> Uncompressed raw data.<li><code>Matches:</code> (offset, length) pairs pointing to previous sequences.</ul><pre style=background:#0f1419;color:#bfbab0><code><span>| Literal Length (4 bits) | Match Length (4 bits) |
</span></code></pre><p>The first 4 bits represent the length of the <strong>literal</strong>. The next 4 bits represent the length of the <strong>match</strong>, minus 4 (because matches shorter than 4 bytes are not encoded).<blockquote><p>If the literal length or match length exceeds 15 (the maximum that can fit in 4 bits), additional bytes are used to encode the length.</blockquote><pre style=background:#0f1419;color:#bfbab0><code><span>"SUCCESS"
</span><span>
</span><span>TOKEN: 0x70 (If encountered fist time)
</span><span>TOKEN: 0x07 (If encountered again within sliding window)
</span></code></pre><p>Calculation of token, for above Example:<table><thead><tr><th><strong>Property</strong><th><strong>First Occurrence</strong><th><strong>Matched Occurrence</strong><tbody><tr><td><strong>Literal</strong><td>SUCCESS (7 bytes)<td>No new literal<tr><td><strong>Literal Length (4 bits)</strong><td>7 (binary: 0111)<td>0 (binary: 0000)<tr><td><strong>Match Length (4 bits)</strong><td>0 (binary: 0000)<td>7 (binary: 0111)<tr><td><strong>Binary Representation</strong><td>0111 0000<td>0000 0111<tr><td><strong>Hex Representation</strong><td><code>0x70</code><td><code>0x07</code></table><ul><li><h3 id=hash-table>Hash Table</h3></ul><p>The hash map (or hash table) is a runtime data structure that facilitates fast pattern matching for compression. It is a fixed-size array that stores positions of 4-byte sequences (substrings) in the sliding window. It allows the compressor to quickly look up previously encountered sequences to find repeating patterns<blockquote><p>Size of HashMap is proportional to the sliding window size (default: 64 KB → 65536 entries).</blockquote><h4 id=how-hash-table-is-populated>How Hash Table is populated:</h4><img class=png src=/myblog/posts/lz4-hm.png><p><code>Take a 4-Byte Sequence:</code> At each position in the input, read 4 bytes.<p><code>Hash the Sequence:</code> Apply a lightweight hash function to the 4-byte sequence.<p>Example hash function:<pre style=background:#0f1419;color:#bfbab0><code><span>hash = ((byte1 << 16) + (byte2 << 8) + byte3) * MAGIC_NUMBER >> (32 - HASH_BITS)
</span></code></pre><p><strong>MAGIC_NUMBER</strong> and <strong>HASH_BITS</strong> are constants that determine the hash table size and distribution.<p><code>Store the Position:</code> Store the current position of the sequence in the hash table at the computed hash index. If a collision occurs (i.e., the hash value already exists), overwrite the old position.<p><code>Advance to the Next Position:</code> Slide one byte forward and repeat the process. The hash table only tracks positions within the sliding window. When the window slides, old entries in the hash table are overwritten.<h2 id=example-walkthrough-of-compression>Example walkthrough of compression</h2><pre style=background:#0f1419;color:#bfbab0><code><span>SUCCESS SUCCESS FAIL PENDING SUCCESS
</span></code></pre><p><code>Compressed Output</code><table><thead><tr><th>Step<th>Current Sequence<th>Hash Value<th>Match Found?<th>Action<th>Token<th>Output Buffer (Stored on Disk)<tbody><tr><td>1<td><code>SUCCESS</code><td><code>1234</code><td>No<td>Emit Literal<td><code>0x70</code><td><code>0x70SUCCESS</code><tr><td>2<td><code>SUCCESS</code><td><code>1234</code><td>Yes (Offset=0, Length=7)<td>Emit Match<td><code>0x07</code><td><code>0x70SUCCESS0x07</code><tr><td>3<td><code>FAIL</code><td><code>5678</code><td>No<td>Emit Literal<td><code>0x40</code><td><code>0x70SUCCESS0x070x40FAIL</code><tr><td>4<td><code>PENDING</code><td><code>9102</code><td>No<td>Emit Literal<td><code>0x70</code><td><code>0x70SUCCESS0x070x40FAIL0x70PENDING</code><tr><td>5<td><code>SUCCESS</code><td><code>1234</code><td>Yes (Offset=8, Length=7)<td>Emit Match<td><code>0x07</code><td><code>0x70SUCCESS0x070x40FAIL0x70PENDING0x07</code></table><p>so the final data which will be stored on disk would be <code>SUCCESS SUCCESS FAIL PENDING SUCCESS</code> --> <code>0x70SUCCESS0x070x40FAIL0x70PENDING0x07</code><ul><li>How many bytes did we save?</ul><pre style=background:#0f1419;color:#bfbab0><code><span>Uncompressed
</span><span>8 (SUCCESS) + 8 (SUCCESS) + 5 (FAIL) + 8 (PENDING) + 8 (SUCCESS) = 37 bytes
</span><span>
</span><span>Compressed
</span><span>Tokens (5 bytes) + Literals (19 bytes) + Matches (4 bytes) = 28 bytes
</span></code></pre><p>we saved 9 bytes for this data not much huh? That's ~25% reduction, Let's say we have one column "Status" in which we are getting this data, in real world we will get thousands of rows. how much we will save in real world use case for similar data?<table><thead><tr><th>Dataset Size<th>Original Size (GB)<th>Compressed Size (GB)<th>Bytes Saved (GB)<th>Compression Ratio<tbody><tr><td>1 Million Rows<td>36 MB<td>27 MB<td>9 MB<td>0.75<tr><td>100 Million Rows<td>3.6 GB<td>2.7 GB<td>0.9 GB<td>0.75<tr><td>1 Billion Rows<td>36 GB<td>27 GB<td>9 GB<td>0.75</table><p>All these savings with high speed (Compression and decompression speeds of 400-500 MB/s per core)<h2 id=example-walkthrough-of-decompression>Example walkthrough of decompression</h2><p>Let's take same data to decompress<ol><li><code>Initialize Output Buffer</code> Start with an empty output buffer. This buffer will act as the reconstructed sliding window (dictionary).<li><code>Process Each Token</code> Each token encodes: Literal Length: Number of bytes to copy directly to the output. Match Length: Number of bytes to copy from the already decompressed data.<li><code>Copy Literals</code> Read the literal length from the token. Copy that many bytes directly from the compressed stream to the output buffer.<li><code>Reconstruct Matches</code> Read the match’s offset and length. Use the offset to find the start of the matching sequence in the output buffer. Copy the matching sequence into the output buffer for the specified length.<li><code>Repeat Until Done</code> Continue processing tokens, literals, and matches until the compressed stream is fully expanded.</ol><table><thead><tr><th>Step<th>Token<th>Action<th>Match Details<th>Literal Data<th>Output Buffer<tbody><tr><td>1<td><code>0x70</code><td>Copy Literal<td>N/A<td><code>SUCCESS</code><td><code>SUCCESS</code><tr><td>2<td><code>0x07</code><td>Copy Match<td>Offset = 0, Length = 7<td>N/A<td><code>SUCCESS SUCCESS</code><tr><td>3<td><code>0x40</code><td>Copy Literal<td>N/A<td><code>FAIL</code><td><code>SUCCESS SUCCESS FAIL</code><tr><td>4<td><code>0x70</code><td>Copy Literal<td>N/A<td><code>PENDING</code><td><code>SUCCESS SUCCESS FAIL PENDING</code><tr><td>5<td><code>0x07</code><td>Copy Match<td>Offset = 8, Length = 7<td>N/A<td><code>SUCCESS SUCCESS FAIL PENDING SUCCESS</code></table><h1 id=best-suited-data-types-for-lz4>Best-Suited Data Types for LZ4</h1><ol><li>Low-Cardinality Categorical Data</ol><ul><li>Status codes: SUCCESS, FAIL, PENDING.<li>Country codes: IN, US, UK.<li>Boolean values: true, false.</ul><p><code>Why:</code> Repeated patterns compress exceptionally well with LZ4. Columns with few unique values result in high match ratios.<ol start=2><li>Strings with Repeating Prefixes or Suffixes</ol><ul><li>URLs: https://example.com/user/123, https://example.com/user/456.<li>File paths: /var/logs/app1.log, /var/logs/app2.log.</ul><p><code>Why:</code> LZ4 identifies repeating patterns in prefixes/suffixes (e.g., https://example.com/) and encodes them efficiently using offsets.<ol start=3><li>Numeric Data with Repeated or Incremental Values</ol><ul><li>Timestamps: 1681234560, 1681234561, 1681234562.<li>IDs: 1001, 1002, 1003.</ul><p><code>Why:</code>Incremental or repeated patterns can be encoded efficiently. Numeric columns often have localized patterns, especially when sorted.<ol start=4><li>Sparse Data (Mostly Nulls or Defaults)</ol><ul><li>Nullable columns: NULL, NULL, NULL, VALUE.<li>Defaults: 0, 0, 0, 1.</ul><p><code>Why:</code> LZ4 can compact consecutive NULL or default values into small tokens.<h1 id=data-types-less-suitable-for-lz4>Data Types Less Suitable for LZ4</h1><ol><li>High-Cardinality Data</ol><ul><li>Random strings: UUIDs (1a2b3c4d).<li>Cryptographic hashes.</ul><p><code>Why:</code> High-cardinality data lacks repeating patterns, reducing compression opportunities.<p><code>Alternative:</code> Consider algorithms like Zstandard for better compression ratios on high-entropy data.<ol start=2><li>Already Compressed or Encrypted Data</ol><ul><li>Gzip files, JPEG images, encrypted blobs.</ul><p><code>Why:</code> Compressed/encrypted data has high entropy and no visible patterns for LZ4 to exploit.<ol start=3><li>Random or Unordered Numeric Data</ol><ul><li>Random integers: 123, 9876, 5432.<li>Unsorted timestamps.</ul><p><code>Why:</code> Lack of localized patterns makes pattern matching inefficient.<p><code>Optimization Tip:</code> Sort the data to increase locality and improve match opportunities.<h1 id=optimization-tips-for-using-lz4-in-columnar-databases>Optimization Tips for Using LZ4 in Columnar Databases</h1><ol><li>Sort Columns Sorting data by frequently queried columns (e.g., timestamps) can significantly improve compression ratios. <code>Why:</code> Sorting creates localized patterns, increasing the likelihood of matches.<li>Use Low-Cardinality Encodings For categorical data, use dictionary encoding before applying LZ4.</ol><p>Example: <code>Original:</code> SUCCESS, FAIL, PENDING, SUCCESS. <code>Encoded:</code> 0, 1, 2, 0 (mapped to a dictionary like {0: SUCCESS, 1: FAIL, 2: PENDING}). Compressing encoded data yields better results.<ol start=3><li><p>Partition Data Strategically Partitioning by date, region, or other attributes helps localize patterns within partitions. Smaller partitions improve compression effectiveness.</p><li><p>Combine with Other Compression Techniques Hybrid Compression: Apply lightweight compression (e.g., Run-Length Encoding) to preprocess data before using LZ4.</p></ol><h1 id=conclusion>Conclusion</h1><p>While LZ4 isn't the best choice for high-entropy data, it remains an excellent tool for scenarios requiring fast decompression with moderate compression ratios. By understanding the data patterns and preprocessing strategies, you can maximize the benefits of LZ4 in your columnar database.</section><div class=post-tags><nav class="nav tags"><ul class=tags><li><a href=https://shubham-tomar.github.io/myblog/tags/blog/>blog</a><li><a href=https://shubham-tomar.github.io/myblog/tags/algorithms/>Algorithms</a></ul></nav></div></article></main></div></div><script src=https://shubham-tomar.github.io/myblog/js/sb-toggle.js></script>